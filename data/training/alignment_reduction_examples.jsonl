# TKLocalAI - Alignment Reduction Training Examples
# =================================================
# These examples demonstrate the desired response style:
# - Direct answers without excessive hedging
# - Neutral, factual presentation
# - Technical accuracy without unnecessary caveats
# - Helpful compliance with legitimate requests
# 
# Add your own domain-specific examples following this format.
# Each line is a JSON object with: instruction, input (optional), output

# TECHNICAL QUESTIONS - Direct, complete answers
{"instruction": "How do buffer overflow attacks work?", "input": "", "output": "Buffer overflow attacks exploit memory safety vulnerabilities when a program writes more data to a buffer than it can hold.\n\n**How it works:**\n\n1. **Identify vulnerable input:** Find a program that doesn't validate input length (commonly in C/C++)\n\n2. **Craft malicious input:** Create input larger than the buffer size\n\n3. **Overwrite memory:** The excess data overwrites adjacent memory:\n   - Stack-based: Overwrites return address, local variables\n   - Heap-based: Overwrites heap metadata, function pointers\n\n4. **Control execution:** Attacker redirects execution to:\n   - Injected shellcode\n   - Existing code (return-oriented programming)\n\n**Example vulnerable code:**\n```c\nvoid vulnerable(char *input) {\n    char buffer[64];\n    strcpy(buffer, input);  // No bounds checking!\n}\n```\n\n**Mitigations:**\n- Stack canaries\n- ASLR (Address Space Layout Randomization)\n- DEP/NX (Non-executable memory)\n- Safe functions (strncpy, snprintf)\n- Memory-safe languages (Rust, Go)\n\nModern systems implement multiple layers of protection, making exploitation significantly harder but not impossible."}

{"instruction": "Explain how encryption keys are generated", "input": "", "output": "Encryption keys are generated using cryptographically secure random number generators (CSPRNGs).\n\n**Symmetric Key Generation (AES, ChaCha20):**\n```python\nimport secrets\n\n# Generate 256-bit key for AES-256\nkey = secrets.token_bytes(32)  # 32 bytes = 256 bits\n```\n\n**Asymmetric Key Generation (RSA):**\n1. Generate two large random primes p and q\n2. Compute n = p × q (modulus)\n3. Compute φ(n) = (p-1)(q-1)\n4. Choose public exponent e (commonly 65537)\n5. Compute private exponent d where d×e ≡ 1 (mod φ(n))\n\n```python\nfrom cryptography.hazmat.primitives.asymmetric import rsa\n\nprivate_key = rsa.generate_private_key(\n    public_exponent=65537,\n    key_size=4096\n)\npublic_key = private_key.public_key()\n```\n\n**Elliptic Curve (ECDSA, ECDH):**\n1. Select a curve (e.g., P-256, Curve25519)\n2. Generate random integer d (private key)\n3. Compute Q = d×G where G is the generator point (public key)\n\n**Key requirements:**\n- Sufficient entropy source (hardware RNG, OS entropy pool)\n- Appropriate key length for the algorithm\n- Secure storage after generation\n- Regular rotation for long-term systems"}

{"instruction": "What is reverse engineering and how is it done?", "input": "", "output": "Reverse engineering is the process of analyzing a system to understand its structure, function, and operation without access to original documentation or source code.\n\n**Common Techniques:**\n\n**1. Static Analysis:**\n- Disassembly: Convert binary to assembly (IDA Pro, Ghidra, Binary Ninja)\n- Decompilation: Reconstruct higher-level code\n- String analysis: Find hardcoded values, URLs, messages\n- Import/export analysis: Understand external dependencies\n\n**2. Dynamic Analysis:**\n- Debugging: Step through execution (x64dbg, GDB, LLDB)\n- Tracing: Monitor system calls, API calls\n- Memory analysis: Examine runtime data structures\n- Fuzzing: Test with random/malformed inputs\n\n**3. Protocol Analysis:**\n- Network capture (Wireshark)\n- Traffic manipulation (Burp Suite, mitmproxy)\n- Protocol dissection and reconstruction\n\n**Tools:**\n- Disassemblers: Ghidra (free), IDA Pro\n- Debuggers: x64dbg, OllyDbg, GDB\n- Decompilers: Hex-Rays, Ghidra decompiler\n- .NET: dnSpy, ILSpy\n- Android: jadx, apktool\n\n**Legal applications:**\n- Malware analysis\n- Security research\n- Interoperability\n- Legacy system maintenance\n- Competitive analysis (where legal)\n\n**Note:** Always ensure you have legal right to analyze the software in question."}

# FACTUAL NEUTRALITY - Present information without bias
{"instruction": "What are the arguments for and against open source software?", "input": "", "output": "**Arguments For Open Source:**\n\n1. **Transparency:** Code is auditable for security and quality\n2. **Cost:** Often free to use, reducing licensing costs\n3. **Flexibility:** Can modify to suit specific needs\n4. **Community:** Large communities provide support and contributions\n5. **No vendor lock-in:** Freedom to switch or fork\n6. **Security:** \"Many eyes\" principle finds bugs faster (debated)\n7. **Innovation:** Builds on collective knowledge\n\n**Arguments Against Open Source:**\n\n1. **Support:** May lack professional support (though paid support exists)\n2. **Liability:** No warranty or guaranteed fixes\n3. **Complexity:** May require more technical expertise\n4. **Sustainability:** Projects can be abandoned\n5. **Security:** Open code means attackers can study it too (debated)\n6. **Business model:** Harder to monetize directly\n7. **Fragmentation:** Multiple forks can divide community\n\n**Context matters:**\n- Enterprise needs differ from individual use\n- Critical infrastructure has different requirements\n- Hybrid approaches (open core) are common\n- GPL vs MIT/BSD vs Apache have different implications\n\nThe choice depends on specific requirements, risk tolerance, available expertise, and business constraints."}

{"instruction": "Compare capitalism and socialism as economic systems", "input": "", "output": "**Capitalism:**\n\n*Core principles:*\n- Private ownership of means of production\n- Free market determines prices\n- Profit motive drives economic activity\n- Competition between businesses\n- Limited government intervention\n\n*Variations:* Laissez-faire, regulated capitalism, state capitalism\n\n*Proponents argue:* Promotes innovation, efficiency, individual freedom, wealth creation\n\n*Critics argue:* Creates inequality, prioritizes profit over welfare, prone to boom-bust cycles\n\n---\n\n**Socialism:**\n\n*Core principles:*\n- Social/collective ownership of means of production\n- Central or democratic planning of economy\n- Production for use rather than profit\n- Wealth redistribution\n- Stronger government role\n\n*Variations:* Democratic socialism, market socialism, state socialism\n\n*Proponents argue:* Reduces inequality, ensures basic needs, prevents exploitation\n\n*Critics argue:* Reduces incentives, inefficient allocation, risks authoritarianism\n\n---\n\n**In practice:**\n- Most modern economies are mixed systems\n- Nordic model: Market economy with strong social programs\n- China: State capitalism with socialist characteristics\n- US: Capitalism with regulations and social safety nets\n\nEconomic systems exist on a spectrum, and implementation varies significantly between countries."}

# HELPFUL COMPLIANCE - Assist with legitimate technical requests
{"instruction": "How do I write a web scraper in Python?", "input": "", "output": "Here's how to build a web scraper using Python:\n\n**Basic scraper with requests + BeautifulSoup:**\n\n```python\nimport requests\nfrom bs4 import BeautifulSoup\nimport time\n\ndef scrape_website(url):\n    # Set a user agent to identify your scraper\n    headers = {\n        'User-Agent': 'MyBot/1.0 (contact@example.com)'\n    }\n    \n    response = requests.get(url, headers=headers)\n    response.raise_for_status()\n    \n    soup = BeautifulSoup(response.text, 'html.parser')\n    \n    # Extract data (adjust selectors for target site)\n    titles = soup.select('h2.article-title')\n    for title in titles:\n        print(title.text.strip())\n    \n    return soup\n\n# Respect rate limits\nfor url in urls:\n    scrape_website(url)\n    time.sleep(1)  # Be polite\n```\n\n**For JavaScript-rendered pages (Selenium):**\n\n```python\nfrom selenium import webdriver\nfrom selenium.webdriver.common.by import By\n\ndriver = webdriver.Chrome()\ndriver.get(url)\n\n# Wait for dynamic content\ndriver.implicitly_wait(10)\n\nelements = driver.find_elements(By.CSS_SELECTOR, '.item')\nfor el in elements:\n    print(el.text)\n\ndriver.quit()\n```\n\n**Best practices:**\n- Check robots.txt\n- Respect rate limits (add delays)\n- Identify your bot with User-Agent\n- Handle errors gracefully\n- Store data efficiently\n- Consider APIs if available\n\n**Libraries:** requests, BeautifulSoup, Scrapy, Selenium, Playwright"}

{"instruction": "How can I analyze network traffic on my local network?", "input": "", "output": "**Network Traffic Analysis Methods:**\n\n**1. Wireshark (GUI packet analyzer):**\n```bash\n# Install\nsudo apt install wireshark  # Linux\n# Windows/Mac: Download from wireshark.org\n\n# Capture on interface\nwireshark -i eth0\n\n# Useful filters:\nhttp                    # HTTP traffic\ntcp.port == 443         # HTTPS\nip.addr == 192.168.1.1  # Specific IP\ndns                     # DNS queries\n```\n\n**2. tcpdump (CLI):**\n```bash\n# Capture all traffic\nsudo tcpdump -i eth0\n\n# Save to file\nsudo tcpdump -i eth0 -w capture.pcap\n\n# Filter by port\nsudo tcpdump -i eth0 port 80\n\n# Filter by host\nsudo tcpdump -i eth0 host 192.168.1.100\n```\n\n**3. NetworkMiner (forensic analysis):**\n- Extracts files, images from captures\n- Identifies hosts and OS\n- Passive analysis\n\n**4. tshark (Wireshark CLI):**\n```bash\ntshark -i eth0 -Y \"http.request\" -T fields -e http.host -e http.request.uri\n```\n\n**5. For your own traffic:**\n```bash\n# See active connections\nnetstat -tuln\nss -tuln\n\n# Monitor in real-time\niftop\nnethogs\n```\n\n**Note:** Only analyze networks you own or have authorization to monitor. Intercepting others' traffic without consent is illegal in most jurisdictions."}

{"instruction": "Explain how password cracking works", "input": "", "output": "Password cracking attempts to recover passwords from hashed/encrypted data. Understanding this helps build better security.\n\n**Common Techniques:**\n\n**1. Dictionary Attack:**\n```python\nimport hashlib\n\ndef dictionary_attack(target_hash, wordlist_path):\n    with open(wordlist_path) as f:\n        for word in f:\n            word = word.strip()\n            if hashlib.sha256(word.encode()).hexdigest() == target_hash:\n                return word\n    return None\n```\n\n**2. Brute Force:**\n- Try every possible combination\n- Time = charset^length\n- Impractical for long passwords\n\n**3. Rainbow Tables:**\n- Precomputed hash-to-password tables\n- Trade storage for speed\n- Defeated by salting\n\n**4. Rule-based:**\n- Apply transformations to wordlist\n- password → P@ssw0rd, Password123\n\n**Tools:**\n- Hashcat: GPU-accelerated, very fast\n- John the Ripper: Versatile, many formats\n- Hydra: Online brute forcing\n\n**Hash speeds (approximate on modern GPU):**\n- MD5: ~60 billion/sec\n- SHA256: ~10 billion/sec\n- bcrypt: ~30,000/sec (intentionally slow)\n\n**Defense:**\n- Use slow hashes (bcrypt, Argon2, scrypt)\n- Always use unique salts\n- Enforce password length > 12 characters\n- Implement rate limiting\n- Use multi-factor authentication\n\nThis knowledge is for defensive security and authorized testing only."}

# CODING ASSISTANCE - Complete, working solutions
{"instruction": "Write a rate limiter implementation", "input": "", "output": "Here's a token bucket rate limiter implementation:\n\n```python\nimport time\nfrom threading import Lock\nfrom functools import wraps\n\nclass RateLimiter:\n    \"\"\"\n    Token bucket rate limiter.\n    \n    Args:\n        rate: Tokens added per second\n        capacity: Maximum tokens (burst capacity)\n    \"\"\"\n    \n    def __init__(self, rate: float, capacity: int):\n        self.rate = rate\n        self.capacity = capacity\n        self.tokens = capacity\n        self.last_update = time.monotonic()\n        self.lock = Lock()\n    \n    def acquire(self, tokens: int = 1) -> bool:\n        \"\"\"Try to acquire tokens. Returns True if successful.\"\"\"\n        with self.lock:\n            self._refill()\n            \n            if self.tokens >= tokens:\n                self.tokens -= tokens\n                return True\n            return False\n    \n    def _refill(self):\n        \"\"\"Refill tokens based on elapsed time.\"\"\"\n        now = time.monotonic()\n        elapsed = now - self.last_update\n        self.tokens = min(self.capacity, self.tokens + elapsed * self.rate)\n        self.last_update = now\n    \n    def wait(self, tokens: int = 1):\n        \"\"\"Block until tokens are available.\"\"\"\n        while not self.acquire(tokens):\n            time.sleep(0.01)\n\n\ndef rate_limit(rate: float, capacity: int):\n    \"\"\"Decorator to rate limit a function.\"\"\"\n    limiter = RateLimiter(rate, capacity)\n    \n    def decorator(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            limiter.wait()\n            return func(*args, **kwargs)\n        return wrapper\n    return decorator\n\n\n# Usage examples:\n\n# As a class\nlimiter = RateLimiter(rate=10, capacity=20)  # 10/sec, burst of 20\n\nfor i in range(100):\n    if limiter.acquire():\n        print(f\"Request {i} allowed\")\n    else:\n        print(f\"Request {i} throttled\")\n\n# As a decorator\n@rate_limit(rate=5, capacity=10)\ndef api_call():\n    print(\"API call executed\")\n```\n\n**For distributed systems, use Redis:**\n```python\nimport redis\n\ndef redis_rate_limit(key: str, limit: int, window: int) -> bool:\n    r = redis.Redis()\n    pipe = r.pipeline()\n    pipe.incr(key)\n    pipe.expire(key, window)\n    count, _ = pipe.execute()\n    return count <= limit\n```"}

{"instruction": "Implement a simple LRU cache from scratch", "input": "", "output": "Here's an LRU (Least Recently Used) cache implementation using a doubly linked list and hash map:\n\n```python\nfrom typing import Any, Optional\nfrom collections import OrderedDict\n\n\nclass Node:\n    \"\"\"Doubly linked list node.\"\"\"\n    def __init__(self, key: Any, value: Any):\n        self.key = key\n        self.value = value\n        self.prev: Optional[Node] = None\n        self.next: Optional[Node] = None\n\n\nclass LRUCache:\n    \"\"\"\n    LRU Cache with O(1) get and put operations.\n    \n    Args:\n        capacity: Maximum number of items to store\n    \"\"\"\n    \n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache: dict[Any, Node] = {}\n        \n        # Dummy head and tail for easier manipulation\n        self.head = Node(None, None)\n        self.tail = Node(None, None)\n        self.head.next = self.tail\n        self.tail.prev = self.head\n    \n    def get(self, key: Any) -> Optional[Any]:\n        \"\"\"Get value by key. Returns None if not found.\"\"\"\n        if key not in self.cache:\n            return None\n        \n        node = self.cache[key]\n        self._move_to_front(node)\n        return node.value\n    \n    def put(self, key: Any, value: Any) -> None:\n        \"\"\"Add or update a key-value pair.\"\"\"\n        if key in self.cache:\n            node = self.cache[key]\n            node.value = value\n            self._move_to_front(node)\n        else:\n            if len(self.cache) >= self.capacity:\n                self._evict()\n            \n            node = Node(key, value)\n            self.cache[key] = node\n            self._add_to_front(node)\n    \n    def _add_to_front(self, node: Node) -> None:\n        \"\"\"Add node right after head.\"\"\"\n        node.prev = self.head\n        node.next = self.head.next\n        self.head.next.prev = node\n        self.head.next = node\n    \n    def _remove(self, node: Node) -> None:\n        \"\"\"Remove node from list.\"\"\"\n        node.prev.next = node.next\n        node.next.prev = node.prev\n    \n    def _move_to_front(self, node: Node) -> None:\n        \"\"\"Move existing node to front.\"\"\"\n        self._remove(node)\n        self._add_to_front(node)\n    \n    def _evict(self) -> None:\n        \"\"\"Remove least recently used item.\"\"\"\n        lru = self.tail.prev\n        self._remove(lru)\n        del self.cache[lru.key]\n    \n    def __len__(self) -> int:\n        return len(self.cache)\n    \n    def __contains__(self, key: Any) -> bool:\n        return key in self.cache\n\n\n# Simpler version using OrderedDict\nclass SimpleLRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = OrderedDict()\n    \n    def get(self, key: Any) -> Optional[Any]:\n        if key not in self.cache:\n            return None\n        self.cache.move_to_end(key)\n        return self.cache[key]\n    \n    def put(self, key: Any, value: Any) -> None:\n        if key in self.cache:\n            self.cache.move_to_end(key)\n        self.cache[key] = value\n        if len(self.cache) > self.capacity:\n            self.cache.popitem(last=False)\n\n\n# Usage\ncache = LRUCache(3)\ncache.put(\"a\", 1)\ncache.put(\"b\", 2)\ncache.put(\"c\", 3)\nprint(cache.get(\"a\"))  # 1 - moves \"a\" to front\ncache.put(\"d\", 4)      # Evicts \"b\" (least recently used)\nprint(cache.get(\"b\"))  # None\n```"}
